{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "\n",
        "!apt-get update\n",
        "!apt-get install portaudio19-dev python3-pyaudio\n",
        "!pip install SpeechRecognition pydub pyaudio wave keyboard\n",
        "!pip install sounddevice soundfile\n",
        "!pip install ipywidgets\n",
        "!pip install transformers\n"
      ],
      "metadata": {
        "id": "CS14so6YVCjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xPUDxoV4iypX"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries\n",
        "import speech_recognition as sr\n",
        "import json\n",
        "import pyaudio\n",
        "import wave\n",
        "import keyboard\n",
        "from pydub import AudioSegment\n",
        "from datetime import datetime\n",
        "import hashlib\n",
        "import sounddevice as sd\n",
        "from google.colab import output\n",
        "from IPython.display import display, Javascript\n",
        "import base64\n",
        "import io\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import os"
      ],
      "metadata": {
        "id": "qky8jw3eVEfT"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "sjyBsBZpM0VW"
      },
      "outputs": [],
      "source": [
        "def load_config(json_file):\n",
        "    \"\"\"\n",
        "    Load configuration from a JSON file.\n",
        "\n",
        "    Parameters:\n",
        "    json_file (str): Path to the JSON file containing configuration.\n",
        "\n",
        "    Returns:\n",
        "    dict: Configuration dictionary.\n",
        "    \"\"\"\n",
        "    with open(json_file, 'r') as file:\n",
        "        config = json.load(file)\n",
        "    return config\n",
        "\n",
        "def speech_recognition_to_text(audio_file_path, language):\n",
        "    \"\"\"\n",
        "    Convert audio to text using SpeechRecognition.\n",
        "\n",
        "    Parameters:\n",
        "    audio_file_path (str): Path to the audio file.\n",
        "\n",
        "    Returns:\n",
        "    str: Recognized text from the audio.\n",
        "    \"\"\"\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    # Load the audio file\n",
        "    audio_file = AudioSegment.from_file(audio_file_path)\n",
        "    audio_file.export(\"temp.wav\", format=\"wav\")\n",
        "\n",
        "    # Use the audio file as the audio source\n",
        "    with sr.AudioFile(\"temp.wav\") as source:\n",
        "        audio = recognizer.record(source)\n",
        "\n",
        "    # Recognize speech using Google Web Speech API\n",
        "    text = recognizer.recognize_google(audio, language=language)\n",
        "\n",
        "    return text\n",
        "\n",
        "def whisper_to_text(audio_file_path):\n",
        "    \"\"\"\n",
        "    Placeholder for converting audio to text using Whisper.\n",
        "    This will be implemented once Whisper is available.\n",
        "\n",
        "    Parameters:\n",
        "    audio_file_path (str): Path to the audio file.\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "def audio_to_text(audio_file_path, config):\n",
        "    \"\"\"\n",
        "    Convert audio to text based on the specified configuration.\n",
        "\n",
        "    Parameters:\n",
        "    audio_file_path (str): Path to the audio file.\n",
        "    config (dict): Configuration dictionary specifying the model to use.\n",
        "\n",
        "    Returns:\n",
        "    str: Recognized text from the audio.\n",
        "    \"\"\"\n",
        "    if config['model'] == 'SpeechRecognition':\n",
        "        language = config['language']\n",
        "        return speech_recognition_to_text(audio_file_path, language)\n",
        "    elif config['model'] == 'Whisper':\n",
        "        return whisper_to_text(audio_file_path)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported model specified in the config file\")\n",
        "\n",
        "def generate_audio_filename():\n",
        "    \"\"\"\n",
        "    Generate a unique filename for the audio file based on the current date and time.\n",
        "\n",
        "    Returns:\n",
        "    str: Generated filename.\n",
        "    \"\"\"\n",
        "    current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    hash_object = hashlib.md5(current_time.encode())\n",
        "    hash_hex = hash_object.hexdigest()\n",
        "    filename = f\"audio-{hash_hex}.wav\"\n",
        "    return filename\n",
        "\n",
        "def record_audio():\n",
        "    \"\"\"\n",
        "    Record audio from the microphone and save it as a WAV file with a unique filename.\n",
        "    Recording will continue until the user presses 'q' to stop.\n",
        "\n",
        "    Returns:\n",
        "    str: Path to the saved audio file.\n",
        "    \"\"\"\n",
        "    filename = generate_audio_filename()\n",
        "    samplerate = 44100  # Hertz\n",
        "    channels = 1\n",
        "\n",
        "    # List all available audio devices\n",
        "    print(sd.query_devices())\n",
        "\n",
        "    # Choose the appropriate input device (you may need to change the index)\n",
        "    input_device_index = 0  # Change this to the correct index for your input device\n",
        "\n",
        "    print('Recording. Press \"q\" to stop recording.')\n",
        "    recording = []\n",
        "\n",
        "    def callback(indata, frames, time, status):\n",
        "        recording.append(indata.copy())\n",
        "        if keyboard.is_pressed('q'):\n",
        "            raise sd.CallbackAbort\n",
        "\n",
        "    with sd.InputStream(samplerate=samplerate, channels=channels, callback=callback, device=input_device_index):\n",
        "        try:\n",
        "            sd.sleep(1000000)  # Keep the recording stream alive\n",
        "        except sd.CallbackAbort:\n",
        "            pass\n",
        "\n",
        "    print('Finished recording')\n",
        "\n",
        "    recording = np.concatenate(recording)\n",
        "    sf.write(filename, recording, samplerate)\n",
        "\n",
        "    return filename\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# JavaScript to record audio\n",
        "RECORD_AUDIO_JS = \"\"\"\n",
        "const sleep = time => new Promise(resolve => setTimeout(resolve, time))\n",
        "const b2text = blob => new Promise(resolve => {\n",
        "  const reader = new FileReader()\n",
        "  reader.onloadend = e => resolve(reader.result)\n",
        "  reader.readAsDataURL(blob)\n",
        "})\n",
        "\n",
        "var record = () => new Promise(resolve => {\n",
        "  navigator.mediaDevices.getUserMedia({ audio: true }).then(stream => {\n",
        "    const recorder = new MediaRecorder(stream)\n",
        "    const data = []\n",
        "    recorder.ondataavailable = event => data.push(event.data)\n",
        "    recorder.start()\n",
        "    const stop = () => {\n",
        "      recorder.stop()\n",
        "      stream.getAudioTracks()[0].stop()\n",
        "    }\n",
        "    const startButton = document.getElementById('startButton')\n",
        "    const stopButton = document.getElementById('stopButton')\n",
        "    startButton.disabled = true\n",
        "    stopButton.disabled = false\n",
        "    stopButton.onclick = () => {\n",
        "      stop()\n",
        "      startButton.disabled = false\n",
        "      stopButton.disabled = true\n",
        "    }\n",
        "    recorder.onstop = async () => {\n",
        "      const audioBlob = new Blob(data, { type: 'audio/wav' })\n",
        "      const text = await b2text(audioBlob)\n",
        "      resolve(text)\n",
        "    }\n",
        "  })\n",
        "})\n",
        "\n",
        "if (!document.getElementById('startButton')) {\n",
        "  const startButton = document.createElement('button')\n",
        "  startButton.id = 'startButton'\n",
        "  startButton.textContent = 'Start Recording'\n",
        "  document.body.appendChild(startButton)\n",
        "  const stopButton = document.createElement('button')\n",
        "  stopButton.id = 'stopButton'\n",
        "  stopButton.textContent = 'Stop Recording'\n",
        "  stopButton.disabled = true\n",
        "  document.body.appendChild(stopButton)\n",
        "  startButton.onclick = async () => {\n",
        "    const data = await record()\n",
        "    google.colab.kernel.invokeFunction('notebook.uploadAudio', [data], {})\n",
        "  }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "def generate_audio_filename():\n",
        "    \"\"\"\n",
        "    Generate a unique filename for the audio file based on the current date and time.\n",
        "\n",
        "    Returns:\n",
        "    str: Generated filename.\n",
        "    \"\"\"\n",
        "    current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    hash_object = hashlib.md5(current_time.encode())\n",
        "    hash_hex = hash_object.hexdigest()\n",
        "    filename = f\"audio-{hash_hex}.wav\"\n",
        "    return filename\n",
        "\n",
        "def upload_audio(b64_audio):\n",
        "    audio_data = base64.b64decode(b64_audio.split(',')[1])\n",
        "    filename = generate_audio_filename()\n",
        "    with open(filename, \"wb\") as f:\n",
        "        f.write(audio_data)\n",
        "    print(f\"Recording saved as {filename}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "9QqXC6F8l5e_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_gpt2_model():\n",
        "    \"\"\"\n",
        "    Load the GPT-2 model and tokenizer.\n",
        "\n",
        "    Returns:\n",
        "    model: The GPT-2 model.\n",
        "    tokenizer: The GPT-2 tokenizer.\n",
        "    \"\"\"\n",
        "    model_name = 'gpt2'\n",
        "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "    return model, tokenizer\n",
        "\n",
        "def generate_text_gpt2(prompt):\n",
        "    \"\"\"\n",
        "    Generate text based on a given prompt using GPT-2.\n",
        "\n",
        "    Parameters:\n",
        "    prompt (str): The input text prompt.\n",
        "\n",
        "    Returns:\n",
        "    str: The generated text.\n",
        "    \"\"\"\n",
        "    model, tokenizer = load_gpt2_model()\n",
        "    inputs = tokenizer.encode(prompt, return_tensors='pt')\n",
        "    input_length = inputs.shape[1]\n",
        "    max_new_tokens = int(input_length * 1.5)\n",
        "    outputs = model.generate(\n",
        "        inputs, max_new_tokens=max_new_tokens, num_return_sequences=1,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return text\n",
        "\n",
        "def generate_text_gpt4(prompt, max_length=150):\n",
        "    \"\"\"\n",
        "    Placeholder for generating text using GPT-4.\n",
        "\n",
        "    Parameters:\n",
        "    prompt (str): The input text prompt.\n",
        "    max_length (int): The maximum length of the generated text. Default is 150.\n",
        "\n",
        "    Returns:\n",
        "    str: The generated text.\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "def adapt_transcribed_text_to_report(transcribed_text, config):\n",
        "    \"\"\"\n",
        "    Adapt the transcribed text to a medical radiology report format using the specified LLM.\n",
        "\n",
        "    Parameters:\n",
        "    transcribed_text (str): The transcribed text.\n",
        "    config (dict): Configuration dictionary specifying the model to use.\n",
        "\n",
        "    Returns:\n",
        "    str: The adapted report text.\n",
        "    \"\"\"\n",
        "    prompt = (\n",
        "        f\"Adapt the following text into a structured radiology report:\\n\"\n",
        "        f\"{transcribed_text}\\n\\nAdapted Report:\\n\"\n",
        "    )\n",
        "\n",
        "    if config['llm'] == 'gpt2':\n",
        "        return generate_text_gpt2(prompt)\n",
        "    elif config['llm'] == 'gpt4':\n",
        "        return generate_text_gpt4(prompt)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported LLM specified in the config file\")\n",
        "\n",
        "def save_text_to_file(text, base_filename, suffix):\n",
        "    \"\"\"\n",
        "    Save text to a file with a specific suffix, preserving the base filename.\n",
        "\n",
        "    Parameters:\n",
        "    text (str): The text to save.\n",
        "    base_filename (str): The base filename to use for the saved file.\n",
        "    suffix (str): The suffix to add to the base filename for the saved file.\n",
        "\n",
        "    Returns:\n",
        "    str: The path to the saved file.\n",
        "    \"\"\"\n",
        "    filename = f\"{base_filename}_{suffix}.txt\"\n",
        "    with open(filename, \"w\") as file:\n",
        "        file.write(text)\n",
        "    return filename"
      ],
      "metadata": {
        "id": "THVBHciv1Bqv"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(json_config_path, audio_file_path=None, record_new_audio=False):\n",
        "    \"\"\"\n",
        "    Main function to load configuration, record audio (if specified), and convert audio to text.\n",
        "\n",
        "    Parameters:\n",
        "    json_config_path (str): Path to the JSON configuration file.\n",
        "    audio_file_path (str): Path, including filename, to the audio file. If recording new audio, this is where it will be saved.\n",
        "    record_new_audio (bool): Whether to record new audio. Default is False.\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    config = load_config(json_config_path)\n",
        "\n",
        "    transcribed_text = audio_to_text(audio_file_path, config)\n",
        "    print(\"You said:\", transcribed_text)\n",
        "\n",
        "    adapted_report = adapt_transcribed_text_to_report(transcribed_text, config)\n",
        "    print(\"Adapted Report:\\n\", adapted_report)\n",
        "\n",
        "    base_filename = os.path.splitext(audio_file_path)[0]\n",
        "    transcribed_text_filename = save_text_to_file(transcribed_text, base_filename, \"transcription\")\n",
        "\n",
        "    adapted_report = adapt_transcribed_text_to_report(transcribed_text, config)\n",
        "\n",
        "    # Save adapted report to file\n",
        "    adapted_report_filename = save_text_to_file(adapted_report, base_filename, \"report\")\n",
        "\n",
        "    print(f\"Transcription saved as: {transcribed_text_filename}\")\n",
        "    print(f\"Adapted report saved as: {adapted_report_filename}\")\n",
        "\n",
        "\n",
        "    return 1"
      ],
      "metadata": {
        "id": "o8RaViHJ1szt"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recording audio\n",
        "output.register_callback('notebook.uploadAudio', upload_audio)\n",
        "display(Javascript(RECORD_AUDIO_JS))"
      ],
      "metadata": {
        "id": "FGvSUNE604J9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "# Save your configuration in a JSON file, e.g., config.json:\n",
        "# {\n",
        "#     \"model\": \"SpeechRecognition\",\n",
        "#     \"language\": \"es-ES\"  # Spanish\n",
        "# }\n",
        "json_config_path = \"/content/config.json\"\n",
        "audio_file_path = \"/content/audio-808c90257ae9624e1f8b7ea3ff030a86.wav\"\n",
        "\n",
        "# Record new audio and transcribe it\n",
        "main(json_config_path, audio_file_path)\n",
        "\n",
        "# Or use an existing audio file\n",
        "# audio_file_path = \"path/to/your/audio_file.wav\"\n",
        "# main(json_config_path, audio_file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKH2MTyqoV9v",
        "outputId": "fc433652-ec3d-473c-df81-84f512f54624"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You said: paciente Juan Pérez fecha de nacimiento 15 de marzo de 1975 fecha del Estudio 23 de julio de 2024 tipo de estudios resonancia magnética RM de la columna lumbar indicación clínica dolor lumbar persistente y radiculopatía hallazgos vértebras las vértebras lumbares presentan altura de alineación normal no se observan fracturas ni lesiones óseas focales discos intervertebrales l1 L2 disco altura y señal normales L2 l3 mínima disminución de la altura del disco con leve producción discal sin compromiso significativo del Canal espinal o foramenes neurales l3 l4 producción discal central y para medial derecha con contacto leves a la raíz nerviosa l4 derecha l4 l5 producción discal difusa que contacte de forma el saco de cal sin estenosis significativa del Canal espinal el 5s 1 nescal para medir a la izquierda que comprime la raíz nerviosa s1 izquierda\n",
            "Adapted Report:\n",
            " Adapt the following text into a structured radiology report:\n",
            "paciente Juan Pérez fecha de nacimiento 15 de marzo de 1975 fecha del Estudio 23 de julio de 2024 tipo de estudios resonancia magnética RM de la columna lumbar indicación clínica dolor lumbar persistente y radiculopatía hallazgos vértebras las vértebras lumbares presentan altura de alineación normal no se observan fracturas ni lesiones óseas focales discos intervertebrales l1 L2 disco altura y señal normales L2 l3 mínima disminución de la altura del disco con leve producción discal sin compromiso significativo del Canal espinal o foramenes neurales l3 l4 producción discal central y para medial derecha con contacto leves a la raíz nerviosa l4 derecha l4 l5 producción discal difusa que contacte de forma el saco de cal sin estenosis significativa del Canal espinal el 5s 1 nescal para medir a la izquierda que comprime la raíz nerviosa s1 izquierda\n",
            "\n",
            "Adapted Report:\n",
            "\n",
            "Paciente Juan Pérez fecha de nacimiento 15 de marzo de 1975 fecha del Estudio 23 de julio de 2024 tipo de estudios resonancia magnética RM de la columna lumbar indicación clínica dolor lumbar persistente y radiculopatía hallazgos vértebras las vértebras lumbares presentan altura de alineación normal no se observan fracturas ni lesiones óseas focales discos intervertebrales l1 L2 disco altura y señal normales L2 l3 mínima disminución de la altura del disco con leve producción discal sin compromiso significativo del Canal espinal el 5s 1 nescal para medir a la izquierda que comprime la raíz nerviosa s1 izquierda\n",
            "\n",
            "Adapted Report:\n",
            "\n",
            "Paciente Juan Pérez fecha de nacimiento 15 de marzo de 1975 fecha del Estudio 23 de julio de 2024 tipo de estudios resonancia magnética RM de la columna lumbar indicación clínica dolor lumbar persistente y radiculopatía hallazgos vértebras las vértebras lumbares presentan altura de alineación normal no se observan fracturas ni lesiones óseas focales discos intervertebrales l1 L2 disco altura y señal normales L2 l3 mínima disminución de la altura del disco con leve producción discal sin compromiso significativo del Canal espinal el 5s 1 nescal para medir a la izquierda que comprime la raíz nerviosa s1 izquierda\n",
            "\n",
            "Adapted Report:\n",
            "\n",
            "Paciente Juan Pérez fecha de nacimiento 15\n",
            "Transcription saved as: /content/audio-808c90257ae9624e1f8b7ea3ff030a86_transcription.txt\n",
            "Adapted report saved as: /content/audio-808c90257ae9624e1f8b7ea3ff030a86_report.txt\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t696fzIvVHak"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}